\documentclass[dvips,12pt]{article}

% Any percent sign marks a comment to the end of the line

% Every latex document starts with a documentclass declaration like this
% The option dvips allows for graphics, 12pt is the font size, and article
%   is the style

\usepackage[pdftex]{graphicx}
\usepackage{url}
\usepackage[pdftex]{xcolor}
\usepackage{amsmath}

% These are additional packages for "pdflatex", graphics, and to include
% hyperlinks inside a document.

\setlength{\oddsidemargin}{0.25in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{0in}
\setlength{\textheight}{8.5in}

\newcommand{\comment}[1]
{{\bfseries \color{red} #1}}

%----------------------------------------------------------------------------------------
%	DOCUMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{2016 RPA Narrative RPA-16-10565\\
Error and Uncertainty Propagation for Fuel Cycle Calculations}

\begin{document}
\noindent\textbf{Technical Workscope Identifier:} FC-5.1b\\
\textbf{Time Frame:} 3 years\\
\textbf{Estimated Cost:} \$800,000


\section{Introduction \& Proposed Scope}
Nuclear fuel cycle simulation tools can have a large
scope of application, from the study of the
behavior of a particular type of fuel or reactor inside an
existing nuclear fleet to the prospective analysis
of a complete nuclear transition. 
Each use case
requires a specific level
of confidence, which are up to now very
poorly assessed, if assessed at all.
%% PPHW: I'm not sure that validation is even possible\\
%% There is a
%% real need of validation the those kind of  
%% calculation, which can hardly been
%% reached. 
Indeed, the only existing way to develop confidence in
any fuel cycle calculation/tool, is to compare
with other similar tools or historical
data.  For the former, the conclusion if often 
a list of why the different software gave
different results with no conclusion on the
precision of any.  The latter only allows
validation of existing concepts and has no impact
on calculations based on the use of new
concepts.

The aim of this project is to add error
propagation capability to the CYCLUS fuel cycle
simulator [1]. Given the use case of predicting the
evolution of a large industrial enterprise in an
uncertain future, nuclear fuel cycle simulations
are generally based on approximate models and
uncertain input data.  Since strict validation is largely
considered to be impractical, such simulations are
seen as indications of trends in future behavior rather than
predictions of that behavior. Nevertheless, it
would be valuable to be able to place some
confidence bounds on those indications, both to
assess the robustness of conclusions that derive
from those indications and to provide information
about the sensitivity of those conclusions to the
uncertain data and algorithms.  Having a broad
distribution for each metric calculated in a fuel
cycle simulation instead of unique values will
allow a better comparison between different fuel
cycle scenarios.  Moreover for some critical
% PPHW: don't want to focus on non-pro so much
%    Not focus of NEUP & not confident we can
%    accomplish enough to make a difference
%analysis such as retrospective non-proliferation
use cases, it could be extremely valuable to add
some degree of confidence on the results of the simulation.
This could result in confidence in the use of the tool for
such uses, and confidence in the conclusions that follow
from those results.

This project
will extend the Cyclus concept of resources to
include error information and then develop a
number of archetypes that can perform operations
to propagate that error in a rigorous fashion.
\comment{PPHW: Can we guarantee ``rigor''?}
The ultimate calculation of fuel cycle performance
metrics will also need to be updated in order to
represent final results as distributions rather
than single values.

\section{Logical Path to Work Accomplishment}
The goal of this project is to add optional
extensions to Cyclus that will allow an assessment
of the error as it propagates through a fuel
cycle.

\subsection{Add uncertainty to ressources}
The first step of this work, is to update the
principal tracked quantity in CYCLUS, the material and
associate the isotopic composition, with the concept of
uncertainty. 
\comment{PPHW: I don't know what this next sentence means?}
Because for this is the first
introduction of uncertainty in CYCLUS (or fuel
cycle calculation tool in general), we will
consider the uncertainty on the material
independent of any previous operation on this
materials.

\comment{
 In general, we need to have more to say here.

 How will we represent uncertainty in a
    composition?

 We should probably have a specific idea for how
    to do this

 To consider: the composition vector in Cyclus
    represents a relative composition.
    Therefore the uncertainty in any single
    nuclide must be related to the uncertainty
    in any other nuclide.

 Also more on: how this representation will be
    transparent to archetypes that don't
    implement error propagation Can we make a
    representation that will still be correct!?!
    Perhaps, if we only allow devs to use the
    available methods to operate on material
    objects.
}

\subsection{Archetype uncertainty management}
When considering a material that is leaving any 
given facility,
 there are three
different sources of uncertainty or error:
\begin{itemize}
\item the uncertainty in the isotopic composition vector
  of the input material,
  $\delta\vec{N}_{in}$,
\item the uncertainty of parameters that define that
  facility, $\tau_{p}$, 
  which correspond to the possible
  variation, or engineering tolerance, in any physics parameter, $i$,
\item the modeling error, $\epsilon_{mod}$, introduced by
  the choice of approximate archetypes models.
\end{itemize}
The uncertainty of the output material composition is a
function of all those uncertainties:
\begin{equation}
\delta \vec{N}_{out} = {\cal F}\{~\delta\vec{N}_{in}~,~\tau_0~,~...~,~\tau_P~,~\epsilon_{mod}~\}.
\end{equation}
In this work we propose to introduce archetypes 
that are able to combine 
all those sources and compute the resulting
uncertainties on the output materials.  The
following sections indicate which specific archetypes
will be considered with some indication of the uncertain
paramters that define those archetypes.  
In some cases, these archetypes are modifications
of those that are already part of the Cycamore set
of base archetypes.  In other cases, entirely new
models will be introduced to enable more advanced
uncertainty propagation.

\subsubsection{Cycamore enrichment facility}

The existing Cycamore enrichment facility produces
enriched uranium on demand, matching the
enrichment of each request, $k$.  Standard models
for enrichment flow rates and separative work
requirements are used only to determine the total
throughput of the facility in any time step as a
function of the:
\begin{itemize}
\item inventory, $F_{tot}$, and composition,
  $x_f$, of feed material,
\item assay of the tails stream, $x_w$, and
\item total separative work, $S_{tot}$.
\end{itemize}

\begin{align*}
  F_k = \frac{x_k - x_w}{x_f - x_w} P_k\qquad\qquad\qquad
  &W_k = \frac{x_k - x_f}{x_f - x_w} P_k\\
  S_k =  P_k\left(2x_k-1\right)ln\frac{x_k}{1-x_k}
         +W_k\left(2x_w-1\right)&ln\frac{x_w}{1-x_w}  
         -F_k\left(2x_f-1\right)ln\frac{x_f}{1-x_f}\\
  \sum_k{F_k} \leq F_{tot}\qquad\qquad
  &\sum_k{S_k} \leq S_{tot}
\end{align*}

With this model, the uncertainty in the product
material is not determined by the inputs or the
model itself.  Instead, the uncertainty in product
enrichment can be introduced with a user-defined
tolerance parameter.  Conversely, uncertainty in
the product enrichment can lead to uncertainty in
the amount of feed that is consumed by any request
and uncertainty in the amount of separative work
capacity that is consumed in order to fullful each
request.  A user-specified tolerance on the tails
assay can also be introduced to contribute to
these uncertainties.

Based on the uncertainty in the product enrichment
(and possibly the tails enrichment), it would be
possible to determine the uncertainty on the
amount of feed material that is consumed by any
given request and on the amount of separative work
used by any given request.

\begin{align*}
  \left(\frac{\delta F_k}{F_k}\right)^2 &= \left(\frac{\delta x_k}{x_k}\right)^2 + \left(\frac{\delta x_w}{x_w}\right)^2 ????\\
  \delta S_k &= ....
\end{align*}


\subsubsection{Other Enrichment Facility??}

\comment{PPHW: Do we want one of these? Possibly
  parametrized by something in the way the cascade
  operates or a single centrifuge?}

\subsubsection{Cyamore separation facility}

The Cycamore separations facility uses a simple
separation matrix approach to distribute every
nuclide, $i$, in the input material across $K$
different streams in the output.

\begin{equation}
N_{i,k} = N_{i,in} \cdot e_{i,k}
\end{equation}

The only parameter which can introduce extra
variance is the separation parameter for nuclide
$i$ in output stream $k$, $e_{i,k} \pm \delta
e_{i,k}$.

Assuming that the uncertainty of the input
material and the tolerance of the separation
parameters are independent, the resulting
uncertainty on the output material composition can
express as :

\begin{equation}
\left(\frac{\delta N_{i}}{N_{j}}\right)^{2}_k = \left(\frac{\delta N_{i}}{N_{i}}\right)^{2}_{in} +  \left(\frac{\delta e_{i}}{e_{i}}\right)^{2}_k 
\end{equation}

\comment{PPHW: We do need to continue to discuss the
  interdependence of these uncertainties between
  different isotopes in the same composition.}

\subsubsection{Cycamore reactor facility}

We are envisaging two kind of the reactor, which
will be both capable of handling uncertainty.  The
reactor archetype included in Cycamore is based on
fixed recipes for input and output materials that
are provided by the user,in addition of all the
classical reactor parameter (batch number, cycle
length, power, capacity factor,...).  Such a model
does not allow any meaningful way to propagate
uncertainty fron any input quantities into the
output composition.  Instead, the user will need
to provide estimates of the sensitivity of the
output recipe to variations in the input recipe.
In general, each output isotope will be sensitive
to the uncertainty in every input isotope,
although in practice some of these can be ignored.

\begin{equation}
\left(\frac{\delta N_j}{N_j}\right)^2 = \sum_i \left(\frac{\delta N_i}{N_i}\right)^2 \sigma_{i,j},
\end{equation}
where $\sigma_{i,j}$ describes the relationship
between the uncertainty in output isotope $j$ and
uncertainty in input isotope $i$.

Variation consideration on those
parameters will affect the discharge time, which
should be very difficult to include in the
uncertainty calculation. Nevertheless, a brute
force study ( also sometimes called "Total Monte
Carlo method") could allow the determine their
impact, running many time the same simulation
choosing randomly the parameter value at each
cycle of the reactor, the distribution of the
results will provides a precise measurement of the
sensivity.\\

The
first one will be built as an upgrade of the
existing CYCAMORE reactor, making it error
aware.

\subsubsection{CLASS-based reactor facility}

The second version of reactor will be able to
calculate the evolution of the fuel provided by
the fuel fabrication (see \S
\ref{sec:fabrication}).  To do so, we propose
investigating two ways, both using pre-trained
models, allowing the prediction of key physics
parameters needed to compute the evolution of a
fuel during the irradiation. It has been proven
that from pre-trained neural network models, one
can predict the evolution of the one group cross
section during the irradiation of the fuel from
its initial isotopic composition, and is working
for a various range of reactor, from LWR to SFR
\cite{Leniau Neural networks,
  Leniau.PHYSOR.2016}.\\ 
The first application using the neural network
predictive models, is to train a model to directly
predict the composition evolution as the function
of the burnup. This application might not work,
since the usage of neural network has been proven
to predict one group macroscopic cross
section.\\ 
If the neural network model fail to directly
predict precisely the isotopic composition
evolution, one have to consider the second option,
which imply to predict the 1 group cross section,
then integrate the Bateman equation.\\

The main reason leading the try of direct
prediction of the isotopic evolution, is the
error/uncertainty propagation. As express
prevsiously :

\begin{equation}
\delta \vec{N}_{out} = {\cal F}\{~\delta\vec{N}_{in}~,~\tau_0~,~...~,~\tau_n~,~\epsilon_{mod}~\}
\end{equation}
The determination and the propagation of all
uncertainty source is, for this kind of reactor, a
complicated matter. The error due to the
computation of the depletion calculation are wild:
\begin{itemize}
\item the error of the neural network predictor,
  $\epsilon^{nn}_{i}$, with $i\in[0..N]$, $N$ the
  number of predicted parameter,
\item the convolution of the uncertainty on the
  material composition with the neural network
  prediction.
\item the calculation error on the data sets used
  to train the neural network, $\epsilon_{T.D.}$.
\end{itemize}
And then can be expressed as :
\begin{equation}
\epsilon_{mod} = {\cal G}\{~\delta\vec{N}_{in}~,~\epsilon^{nn}_{0}~,~...~,~\epsilon^{nn}_{n}~,~\epsilon_{T.D.}~\}
\end{equation}

Because, the predictive model are trained on
sample populated using few thousand of depletion
calculation, which are subject to computation
error, $\epsilon_{T.D.}$. On one side, a depletion
calculation take as input, the nuclear data. Those
nuclear data are interpolated/extrapolated from
many different experimental measurement using many
different models. Therefore the nuclear data
contain uncertainty...  Those uncertainty are
extremely difficult to propagate properly through
a full depletion calculation because of the
coupling between neutron transport and depletion
calculation: the composition of the fuel impact
the shape of the neutron spectrum, which impact
the reaction rate on the nuclei... On the other
side, the depletion calculation require different
approximation to be completed. There is nearly
impossible using Monte Carlo technique on a PWR
full core calculation due to source convergence
issue. It is also extremely complicate to follow
precisely the different reactor parameter, such as
boron concentration, rod control management,
charge factor evolution, neutron leakage... The
study and the propagation of the modeling
uncertainty, such as the modeling simplification
and the nuclear data uncertainty is way beyond the
scope of this project...\\ 
This require a full dedicated research project
(and probably more). Therefore, those error,
$\epsilon_{T.D.}$, will not be considered on the
first version of this work. This might need to be
reconsidered when the depletion calculation error
propagation capacity will have done important
progress.\\
The direct error induced by the use of predictive
model, $\epsilon^{nn}_{i}$ on each parameter, $i$,
need to be assessed. This could be performed with
a mapping the error on the isotopic space
populated with the training sample. This will
allow to determine the error of the model on each
point on the isotopic space populated. We might
use then a other neural network, or other
interpolation method to predict the error of the
prediction as the function of the isotopic
composition.\\
Once we have a working predictive model and a map
of the error on the prediction, one need to build
the covariance matrix which will allow to
convolute the uncertainty on the input material,
$\delta N_{in}$, with the prediction of the
model.\\


If the direct prediction of the composition is not
precise enough, one have to use solve Bateman
equation using predicted one group cross section
and then compute the error coming from a numerical
resolution of the Bateman equation and propagate
the error of the one group cross section.  The
Bateman equation resolution will be a step by step
process. After having discretize the irradiation
time (or burnup), one will use the model to
predict the cross section at each time step
(closer the time step are preciser the calculation
will be) and then solve numerically the Bateman
equation step after step, ending with the final
isotopic composition of the fuel. Because the
predictive model will be able to predict the one
cross section as the function of time (or burnup),
one should be able to propagate those error using
sensitivity analysis.  The time discretization as
well as the other approximation require to solve
the Bateman equation will also introduce
computation error that need to be determined and
added to the final uncertainty. This could be made
with the comparison of depletion calculation made
with those extra approximation with the reference
one performed using the same modeling
approximation as the training depletion all along
the isotopic space.



\subsubsection{Fabrication} \label{sec:fabrication}
The aim of the fuel fabrication is to mix
different incoming material streams in order to
build a fuel which validate the neutronics/physics
requirement of the reactor. Depending of the
reactor, the criterium could be various. We are
considering in the first time including
fabrication model for MOX fuel only, in LWR and
SFR, used as burner and breeder for SFR. One will
use algorithm building fuel allowing to build fuel
reaching the targeted burnup according to either
criticality criterium either conversion ratio
criterium.  Those algorithm will relies on the
capabilities of some predictive model to predict
the maximal achievable burnup depending on the the
criticality or conversion ratio evolution
according to burnup.  The predictive model as the
reactor model, will be based on the use of neural
network formerly trained on the same set of
training depletion calculation used for the
reactor models. The capability of the neural
network have been proven to predict the evolution
of the criticality in PWR reactor using MOX fuel
\cite{Leniaux.NN, CLASS_UserManual}, as well as
the the initial criticality of MOX fuel in SFR
\cite{CLASS UserManual} and should be possible to
extend it to conversion ratio evolution.

The error/uncertainty propagation for fuel
fabrication should be pretty similar than for
reactor. Indeed the uncertainty can be expressed
as :
\begin{equation}
\delta \vec{N}_{out} = {\cal H}\{~\delta\vec{N}_{in}~,~\epsilon_{mod}~\}.
\end{equation}
In this case there is no tolerance, since the
parameter are goal to achieve, not physicals
characteristics. As well as previously the error
of the model can be expressed as :
\begin{equation}
\epsilon_{mod} = {\cal K}\{~\delta\vec{N}_{in}~,~\epsilon^{nn}_{0}~,~...~,~\epsilon^{nn}_{n}~,~\epsilon_{T.D.}~\},
\end{equation}
 where $\epsilon^{nn}_{i}$ represent the error on
 the prediction of the parameter $i$ by the neural
 network predictive model and $\epsilon_{T.D.}$
 the error due to the error on the depletion
 calculation composing the training set, which
 will not be considered since we dont have any way
 to correctly estimate it.\\
 
 As for the reactor model, the $\epsilon^{nn}_{i}$
 component of the error can be determined through
 a mapping of the error along the isotopic space,
 and the impact of the material input uncertainty
 needed the be assessed by the calculation of the
 covariance matrix which need to be build.

\subsection{Problems/Applications/Validations}
During the realization of this work we would like
to validate each step of the uncertainty
propagation process. First, with a mid/early-term
validation, after the enrichment facilities, the
separation and the recipes reactor will be
implemented, it will be possible to confirm the
uncertainty is correctly propagated, using a brute
force validation (with the "Total Monte Carlo"
method). This validation will be continued with
new archetypes will be implemented in CYCLUS...\\
An other gaol we want to achieve, is an
sensitivity analysis, allowing to determine the
impact of the different
uncertainty/error/tolerance on the final
calculation uncertainty. This should allow to
define precisely where the future effort should be
focus to reduce those uncertainty sources
accordingly to the object of the calculation and
also to validate (or un-validate) the use of fuel
cycle simulation tool for some specialized study
(such as non-proliferation study...)\\
With all the necessary components in place, a
series of demonstration simulations will be
conducted using fuel cycles of increasing
complexity: once through, MOX LWR recycle, and
fast reactor recycle.  These scenarios will be
constructed to highlight the role of error and
uncertainty and identify metrics in which the
presence uncertainty may impact fuel cycle
analysis conclusions.



%\textit{We imagine 3 step in the final
%phase. First we would like to step up a testing
%mechanism, based on simply brute force the
%uncertainty propagation in the fuel cycle
%calculation by using some kind of Total monte
%Carlo, allowing all parameters to fluctuate
%accordingly to their respective uncertainty on
%many integration of the same calculation. The
%result distribution can be read as a direct
%measure of the uncertainty on the final parameter
%and will be compared to the direct uncertainty
%propagation calculation as a validation of all
%the method previously presented. This method will
%(turning on the uncertainty on each parameter one
%by one) to validate the uncertainty propagation
%on each parameter...\\

%One need nevertheless keep in mind that
%everything is never perfect, and one should
%always try to improve. To do so it is required to
%identify the most problematic issue and solve
%it. In this particular case, one need to identify
%what is the uncertainty gaol depending on the
%application of the fuel calculation, of course
%the precision goal is very different when one
%doing a prospective calculation versus a
%non-proliferation retrospective
%analysis... Knowing it, one very important of
%this project is it could allow through
%sensitivity analysis to identify the biggest
%uncertainty source, and help to focus to improve
%it.\\ 

%That is why, in addition of the TMC test tool, I
%would like to develop a tool/method to
%systematically allows user to perform sensitivity
%analysis applied to their calculation allowing us
%to improve future models dedicated to some
%precise use of the CYCLUS tool.\\

%Finally, we would like
%Third step : application to simple case : PWR, transition from PWR to FBR...}
\section{Relevance of Proposed Research}
This proposal aims to provide an important feature
needed in the fuel cycle simulator.  Given the
appropriate estimation of the error relative to
any fuel cycle simulation, the simulator would be
able to make decisions about fuel cycle transition
like fuel reprocessing, or the launching of new
technologies or types of reactors. Furthermore,
the project will be one of the first of its kind
to introducing error propagation in fuel cycle
calculation, increasing the utility of the Cyclus
kernel. Since the precision of fuel cycle tool
have never been assessed, this work might the
first step providing more confidence in the fuel
cycle calculation. And even if this wok will be
applied to the fuel cycle simulation tool CYCLUS,
the concept should be a theoretically applicable
on any agent based fuel cycle simulation
tool.\\ 
Additionally, new archetypes will be contributed
to the Cyclus ecosystem, including not only error
propagation but also different fuel fabrication
methods, cross-section prediction models and a
Bateman equation solver. These features will
permit future comparison between the different
fuel fabrication models and improve the user
experience and confidence in the interpretations
of Cyclus simulations.

\pagebreak
\section{Milestone Task Listing}
This research project consist in four major tasks
that could be conducted in parallel.  The first
one will be very short ($<$ 6 month), dedicated to
update CYCLUS and allow it to handle
uncertainty. The second one should be the longer
task (12 - 24 months) where the models will be
developed. The predictive model development
can/should/will be started at the start of the
project. The third will be started after the end
of the TASK 1 and corresponds to CYCLUS archetypes
update and included in a separated package. The
development of some archetypes will depends on the
progress on the TASK2. The last task is the
validation and application one and will be started
with the completion of the different
TASK3-subtasks. The ideal progression is
represented on the figure \ref{fig:progression}.
\begin{figure}[h!]
\centering
\includegraphics[angle=270,width=1\textwidth]	{TIMESCHEDULE}
\caption{Preliminary schedule of the project, with the different Task (T\#) (1 in blue, 2 orange, 3 red, 4 green) and the corresponding subtask (SB\#).}
\label{fig:progression}
\end{figure}

\noindent\textbf{TASK 1:} CYCLUS update for uncertainty awareness
\begin{itemize}
\item subtask 1: update material to uncertainty,
\item subtask 2: validate the backward
  compatibility,
\item subtask 3: Add a default uncertainty
  behavior when using both uncertainty aware
  archetypes and standard one in the same time ?
\end{itemize}

\noindent\textbf{TASK 2:} Updating the CYCLUS Archetypes to uncertainty management
\begin{itemize}
\item subtask 1: enrichment facility, 
\item subtask 2: separation facility,
\item subtask 3: recipe reactor,
\item subtask 4: reactor archetypes, depletion
  calculation/prediction, uncertainty propagation,
\item subtask 5: fuel fab archetypes, mixing
  calculation/prediction, uncertainty propagation.
\end{itemize}

\noindent\textbf{TASK 3:} Modeling development
\begin{itemize}
\item subtask 1: isotopic space definition,
  training sample realization
\item subtask 2: reactor models development:
  parameter prediction, error analysis
\item subtask 3: fuel fabrication model
  development: parameter prediction, error
  analysis
\end{itemize}
 
\noindent\textbf{TASK 4:} Validation \& application
\begin{itemize}
\item subtask 1: validation of the overall process
  with simple calculation : enrichment +
  separation + recipe reactor
\item subtask 2: validation of modeling
  capabilities (Fab + reactor)

\item subtask 3: exemple calculation: PWR,
  transition from PWR to FBR
\item subtask 4: full sensitivity analysis

\item subtask 5: time dependent parameters
  sensitivity analysis (discharge burnup, capacity
  factor...)

\item subtask X: comparison with other physic
  modeling capabilities such as Bright-Lite ?
\end{itemize}






 







%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\bibliographystyle{unsrt}

\bibliography{}

%----------------------------------------------------------------------------------------


\end{document}
